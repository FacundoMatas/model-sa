{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import *\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from os import scandir, getcwd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leemos el save del clasificador y el set de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = files_path=getcwd()\n",
    "# file = \"binario_experimento6\"\n",
    "# directory = '\\\\binario\\\\'\n",
    "file = \"experimento6\"\n",
    "directory = '\\\\ternario\\\\'\n",
    "filename= path+directory+file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificadores = pickle.load(open(file+'.sav', 'rb'))\n",
    "\n",
    "testing_set = pickle.load(open('testing_set_'+file+'.txt', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicamos la evaluación y guardamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1 = open(filename + '.txt',\"w\") \n",
    "\n",
    "accuracyDict = {}\n",
    "  \n",
    "# \\n is placed to indicate EOL (End of Line) \n",
    "file1.write(\"Resultados \"+ filename + ' \\n\\n') \n",
    "\n",
    "writer = pd.ExcelWriter(path+directory+'clasification_report_'+file+'.xlsx', engine='xlsxwriter')\n",
    "writerCM = pd.ExcelWriter(path+directory+'confusion_matrix_'+file+'.xlsx', engine='xlsxwriter')\n",
    "for (nombre,clasificador) in clasificadores.items():\n",
    "    ref = []\n",
    "    test = []\n",
    "    for i, (feats, label) in enumerate(testing_set):        \n",
    "        ref.append(label)\n",
    "        test.append(clasificador.classify(feats))\n",
    "    file1.write(\"***** METRICAS CLASIFICADOR \"+nombre+\" *****\\n\\n\") \n",
    "    file1.write(\"Exactitud (accuracy) \" +  str(accuracy(ref, test)*100)+\"\\n\") \n",
    "    reference_set = set(ref)\n",
    "    test_set = set(test)\n",
    "    file1.write(\"Precision \" +str(precision(reference_set, test_set))+\"\\n\")\n",
    "    file1.write(\"Recall \" +str(recall(reference_set, test_set))+\"\\n\")\n",
    "    file1.write(\"F measure \" + str(f_measure(reference_set, test_set))+\"\\n\\n\")\n",
    "    file1.write(\"Matriz de confusión \\n\")\n",
    "    file1.write(str(ConfusionMatrix(ref, test)))\n",
    "    file1.write('\\n')\n",
    "    file1.write(\"Reporte de clasificación\\n\")\n",
    "    file1.write(metrics.classification_report(ref,test,digits=3)+'\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    data = {'y_Predicted': test,\n",
    "        'y_Actual':   ref\n",
    "        }\n",
    "    \n",
    "    df_cm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(df_cm['y_Actual'], df_cm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    \n",
    "    confusion_matrix.to_excel(writerCM,sheet_name=nombre) \n",
    "    \n",
    "    report = metrics.classification_report(ref, test, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_excel(writer,sheet_name=nombre)\n",
    "    \n",
    "    \n",
    "    file1.write(\"****************************************\\n\\n\\n\\n\")\n",
    "    \n",
    "    accuracyDict[nombre] = str(accuracy(ref, test)*100)\n",
    "\n",
    "df_ac = pd.DataFrame([accuracyDict])   \n",
    "df_ac = df_ac.T\n",
    "df_ac.to_excel(path+directory+'accuracy_'+file+'.xlsx')\n",
    "\n",
    "file1.close() #to change file access modes \n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
