{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import scandir, getcwd\n",
    "from nltk import ngrams\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.classify.util import accuracy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path=getcwd()\n",
    "file = 'tweets_preprocessed.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si se consideran tweets neutros (etiquetados como 2), la condicion es que el dataset filtre los tweets menores a 3, en caso contrario menores a 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_ds = ds[ds.sentiment < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesamiento(row):\n",
    "    replaced = re.sub(\"(?:^|\\s)[＃#]{1}(\\w+)\",'',row['text'] )\n",
    "    replaced_wo_user= re.sub(\"(?:^|\\s)[＠ @]{1}([^\\s#<>[\\]|{}]+)\", '', replaced)\n",
    "    replaced_links=re.sub(\"/[\\w.-]*\",'',replaced_wo_user) \n",
    "    replaced_links = replaced_links.replace(\"\\r\",\" \")\n",
    "    replaced_links = replaced_links.replace(\"\\n\",\" \")\n",
    "    \n",
    "    a,b = 'áéíóúü','aeiouu'\n",
    "    trans = str.maketrans(a,b)\n",
    "    replaced_links = replaced_links.translate(trans)\n",
    "    \n",
    "    return replaced_links   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean1 = filter_ds\n",
    "# df_clean1['text'] = df_clean1.apply(preprocesamiento, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean1\n",
    "df_clean[\"text\"] = df_clean['text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mirando como se le cae el ojo a a dietrich cua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gracioso es que cada vez que aumentan dietric...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en ya planteaba que las fuerzas armadas tenian...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gato que corrio a las ratas de casa rosada qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>este delincuente que es dueño de todo moro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>el festejo del globoludo por la noticia de es ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>boudou preso con condena cuadernogate sueños c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>por eso despues los cinicos hipocritas cargan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pueblo pide se vote la ley pinedo de extincio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>somos una joda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hoy salimos a escuchar a los vecinos estuvimos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>la verdad es que picheto tendria que estar col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>por que me bloqueo y si les busco guitarra y v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>los zurdos y los k seguiran atacando al presi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>el codigo penal no se cambia tan facil que es...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>con boudou adentrocarlotto hace casting para e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tengo entendido que vuelve al congreso por el...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>con la historia de las fuerzas armadas en arge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>te perdonan el haberles quitado en negociado ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>me acorde cuando hace mucho la palabra golpist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>argentina le dio un ejemplo al mundo al advers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>q la q le dio a tu vieja y a todos los planer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>cinco años de prision injustamente para el com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>uy uy uy que me dicen del dedito que le meten ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>que te bajen la urna con buena ondaes un buen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>jorge sappia presidente organo maximo la conve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>a colar el aborto por la reforma de codigo pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>en el le cuentan a la gente que a cristina se ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>aterra el antecedente inmediato de fuerzas arm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>gracias compañero amado boudou por devolverle ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>dietrich subi el transporte si queres pero no ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>indignados por el periodista delincuente en ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>no hay lluvia que detenga el camino del cambio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6555</th>\n",
       "      <td>dice dietrich que volar en la argentina es muy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>en estos de macri en los cuales hay hay menos ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>nos robaron mal a vos a mi al que tiene y al q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>no solo es por haber eliminado el curro de las...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6570</th>\n",
       "      <td>a vos pibe que no viviste otras epocas esto es...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>buscas revancha en el diccionario y aparece la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>de romper las pelotas  re pedo lo hacen si de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>es nuestra y de toda la oposicion dejamos q e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6579</th>\n",
       "      <td>buenos dias gente yo llego temprano a la casa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>lo que le pasa a boudou es injusto pero es hab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>y vos que creias te verseaba diciendote que cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>el chetaje salio a timbrear y tomar a la gente...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>vieja jubilada de la minima le dio un pico de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>no se aprueba que sea por decreto por el ejec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>otro aumento</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>al hdp de nk boudou y cfk casi quiebran la ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>creer a la gente que podian viajar en bondi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>se vote con integridad honestidad estamos muy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>tene cuidado con el que los delincuentes puede...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>hoy estuvimos en escuchando a los vecinos junt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>idea que se les cae al mejor equipo de los ul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>detuvieron a un periodista acreditado en casa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>la gente que aplaude la condena a boudou deber...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6620</th>\n",
       "      <td>hoy salimos a escuchar a los vecinos de banfie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>bien el presidente dandole importancia a las f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6629</th>\n",
       "      <td>me parece muy relevante el cambio que impulso ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>el decidio de un plumazo romper un consenso po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     mirando como se le cae el ojo a a dietrich cua...          1\n",
       "1      gracioso es que cada vez que aumentan dietric...          0\n",
       "4     en ya planteaba que las fuerzas armadas tenian...          0\n",
       "6      gato que corrio a las ratas de casa rosada qu...          1\n",
       "7         este delincuente que es dueño de todo moro...          0\n",
       "10    el festejo del globoludo por la noticia de es ...          0\n",
       "14    boudou preso con condena cuadernogate sueños c...          1\n",
       "19    por eso despues los cinicos hipocritas cargan ...          0\n",
       "21     pueblo pide se vote la ley pinedo de extincio...          1\n",
       "23                                    somos una joda             0\n",
       "24    hoy salimos a escuchar a los vecinos estuvimos...          1\n",
       "25    la verdad es que picheto tendria que estar col...          1\n",
       "26    por que me bloqueo y si les busco guitarra y v...          1\n",
       "27     los zurdos y los k seguiran atacando al presi...          1\n",
       "29     el codigo penal no se cambia tan facil que es...          1\n",
       "30    con boudou adentrocarlotto hace casting para e...          0\n",
       "31     tengo entendido que vuelve al congreso por el...          1\n",
       "38    con la historia de las fuerzas armadas en arge...          0\n",
       "39     te perdonan el haberles quitado en negociado ...          1\n",
       "40    me acorde cuando hace mucho la palabra golpist...          0\n",
       "41    argentina le dio un ejemplo al mundo al advers...          1\n",
       "43     q la q le dio a tu vieja y a todos los planer...          1\n",
       "44    cinco años de prision injustamente para el com...          0\n",
       "47    uy uy uy que me dicen del dedito que le meten ...          0\n",
       "51    que te bajen la urna con buena ondaes un buen ...          1\n",
       "55    jorge sappia presidente organo maximo la conve...          0\n",
       "56     a colar el aborto por la reforma de codigo pe...          1\n",
       "57    en el le cuentan a la gente que a cristina se ...          0\n",
       "59    aterra el antecedente inmediato de fuerzas arm...          0\n",
       "60    gracias compañero amado boudou por devolverle ...          1\n",
       "...                                                 ...        ...\n",
       "6547  dietrich subi el transporte si queres pero no ...          0\n",
       "6552  indignados por el periodista delincuente en ca...          0\n",
       "6554    no hay lluvia que detenga el camino del cambio           1\n",
       "6555  dice dietrich que volar en la argentina es muy...          1\n",
       "6562  en estos de macri en los cuales hay hay menos ...          1\n",
       "6568  nos robaron mal a vos a mi al que tiene y al q...          0\n",
       "6569  no solo es por haber eliminado el curro de las...          0\n",
       "6570  a vos pibe que no viviste otras epocas esto es...          0\n",
       "6575  buscas revancha en el diccionario y aparece la...          0\n",
       "6577   de romper las pelotas  re pedo lo hacen si de...          0\n",
       "6578   es nuestra y de toda la oposicion dejamos q e...          0\n",
       "6579  buenos dias gente yo llego temprano a la casa ...          1\n",
       "6581  lo que le pasa a boudou es injusto pero es hab...          0\n",
       "6588  y vos que creias te verseaba diciendote que cu...          0\n",
       "6595  el chetaje salio a timbrear y tomar a la gente...          0\n",
       "6599   vieja jubilada de la minima le dio un pico de...          0\n",
       "6600   no se aprueba que sea por decreto por el ejec...          0\n",
       "6601                                      otro aumento           0\n",
       "6602   al hdp de nk boudou y cfk casi quiebran la ca...          0\n",
       "6604        creer a la gente que podian viajar en bondi          0\n",
       "6606   se vote con integridad honestidad estamos muy...          0\n",
       "6609  tene cuidado con el que los delincuentes puede...          0\n",
       "6612  hoy estuvimos en escuchando a los vecinos junt...          1\n",
       "6613   idea que se les cae al mejor equipo de los ul...          0\n",
       "6616  detuvieron a un periodista acreditado en casa ...          0\n",
       "6618  la gente que aplaude la condena a boudou deber...          1\n",
       "6620  hoy salimos a escuchar a los vecinos de banfie...          1\n",
       "6626  bien el presidente dandole importancia a las f...          1\n",
       "6629  me parece muy relevante el cambio que impulso ...          1\n",
       "6634  el decidio de un plumazo romper un consenso po...          0\n",
       "\n",
       "[2792 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['text'] = df_clean['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mirando como se le cae el ojo a a dietrich cua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gracioso es que cada vez que aumentan dietric...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en ya planteaba que las fuerzas armadas tenian...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gato que corrio a las ratas de casa rosada qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>este delincuente que es dueño de todo moro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  mirando como se le cae el ojo a a dietrich cua...          1\n",
       "1   gracioso es que cada vez que aumentan dietric...          0\n",
       "4  en ya planteaba que las fuerzas armadas tenian...          0\n",
       "6   gato que corrio a las ratas de casa rosada qu...          1\n",
       "7      este delincuente que es dueño de todo moro...          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean = df_clean.reset_index()\n",
    "df_clean=df_clean[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos bolsas de palabras que serviran de entrada al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para experimentos donde se utilizan ngramas, pueden usarse Bigramas o Trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_features(words):    \n",
    "#     score = BigramAssocMeasures.chi_sq\n",
    "#     bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "#     #bigram count\n",
    "\n",
    "#     bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "#     bigrams = bigram_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "#     return dict([(word, True) for word in itertools.chain(words, bigrams)])\n",
    "\n",
    "\n",
    "\n",
    "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "    score = TrigramAssocMeasures.chi_sq\n",
    "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "    \n",
    "\n",
    "    \n",
    "    finder = TrigramCollocationFinder.from_words(words)\n",
    "    trigrams = finder.score_ngrams(trigram_measures.raw_freq)\n",
    "\n",
    "    return dict([(word, True) for word in itertools.chain(words, trigrams)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para eliminar las stopwords de los nuevos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#SIN USAR NGRAMS\n",
    "# def bag_of_words_not_in_set(words, badwords):\n",
    "#     return bag_of_words(set(words) - set(badwords))\n",
    "\n",
    "#USANDO NGRAMS\n",
    "def bag_of_words_not_in_set(words, badwords):\n",
    "    return create_word_features(set(words) - set(badwords))\n",
    "\n",
    "#SIN ELIMINAR LAS PALABRAS MAS FRECUENTES\n",
    "def bag_of_non_stopwords(words, stopfile='spanish'):\n",
    "    badwords = stopwords.words(stopfile)\n",
    "    return bag_of_words_not_in_set(words, badwords)\n",
    "\n",
    "# # #ELIMINANDO LAS PALABRAS MAS FRECUENTES\n",
    "# def bag_of_non_stopwords(words, stopfile='spanish'):\n",
    "#     badwords = stop_words\n",
    "#     return bag_of_words_not_in_set(words, badwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función que realiza el stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta función llama a las demás de acuerdo al experimento a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #STEMMER\n",
    "# def label_feats_from_corpus(corp, feature_detector=bag_of_non_stopwords):\n",
    "#     label_feats = collections.defaultdict(list)\n",
    "#     for fileid in range(corp['sentiment'].count()):\n",
    "#             feats = feature_detector(stem_tokens(str(corp['text'][fileid]).split(),stemmer))\n",
    "# #             print(feats)\n",
    "#             label_feats[int(corp['sentiment'][fileid])].append(feats)\n",
    "#     return label_feats\n",
    "\n",
    "\n",
    "\n",
    "def label_feats_from_corpus(corp, feature_detector=bag_of_non_stopwords):\n",
    "#     print(corp)\n",
    "    label_feats = collections.defaultdict(list)\n",
    "    for fileid in range(corp['sentiment'].count()):         \n",
    "        feats = feature_detector(str(corp['text'][fileid]).split())\n",
    "        label_feats[int(corp['sentiment'][fileid])].append(feats)\n",
    "    return label_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función que divide el conjunto de datos en entrenamiento y prueba. Por defecto la division es al 70% , al menos que se indique otro valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label_feats(lfeats, split=0.7):\n",
    "    train_feats = []\n",
    "    test_feats = []\n",
    "    for label, feats in lfeats.items():\n",
    "        cutoff = int(len(feats) * split)\n",
    "        train_feats.extend([(feat, label) for feat in feats[:cutoff]])\n",
    "        test_feats.extend([(feat, label) for feat in feats[cutoff:]])\n",
    "#         print(train_feats)\n",
    "    return train_feats, test_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formamos los conjuntos aptos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lfeats = label_feats_from_corpus(df_clean)\n",
    "#lfeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividimos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_set, testing_set = split_label_feats(lfeats, split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos los clasificadoresque se van a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier,RidgeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neural_network import MLPClassifier, BernoulliRBM, BernoulliRBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entreamiento de cada clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 79.06976744186046\n",
      "SGDClassifier_classifier accuracy percent: 76.74418604651163\n",
      "RidgeClassifier_Classifier accuracy percent: 76.20751341681574\n",
      "MNB_classifier accuracy percent: 75.49194991055455\n",
      "BernoulliNB_classifier accuracy percent: 66.90518783542039\n",
      "ComplementNB_classifier accuracy percent: 77.6386404293381\n",
      "SVC_classifier accuracy percent: 66.7262969588551\n",
      "LinearSVC_classifier accuracy percent: 76.74418604651163\n",
      "NuSVC_classifier accuracy percent: 76.02862254025044\n"
     ]
    }
   ],
   "source": [
    "#LINEALES\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression(multi_class='ovr'))\n",
    "LogisticRegression_classifier._vectorizer.sort = False\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier._vectorizer.sort = False\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "\n",
    "RidgeClassifier_Classifier = SklearnClassifier(RidgeClassifier())\n",
    "RidgeClassifier_Classifier._vectorizer.sort = False\n",
    "RidgeClassifier_Classifier.train(training_set)\n",
    "print(\"RidgeClassifier_Classifier accuracy percent:\", (nltk.classify.accuracy(RidgeClassifier_Classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "#BAYESIANOS\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier._vectorizer.sort = False\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier._vectorizer.sort = False\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "ComplementNB_classifier = SklearnClassifier(ComplementNB())\n",
    "ComplementNB_classifier._vectorizer.sort = False\n",
    "ComplementNB_classifier.train(training_set)\n",
    "print(\"ComplementNB_classifier accuracy percent:\", (nltk.classify.accuracy(ComplementNB_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "#SVM\n",
    "\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier._vectorizer.sort = False\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier._vectorizer.sort = False\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier._vectorizer.sort = False\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.metrics import edit_distance\n",
    "from nltk.metrics.scores import precision\n",
    "from nltk.metrics.scores import recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos los clasificadores en archivos separados, asi como el set de test del experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificadores = {\n",
    "    \"Regresion logistica\":LogisticRegression_classifier,\n",
    "    \"SGD\":SGDClassifier_classifier,\n",
    "    \"Ridge\":RidgeClassifier_Classifier,\n",
    "    \"MNB\":MNB_classifier,\n",
    "    \"Bernoulli NB\":BernoulliNB_classifier,\n",
    "    \"Complement NB\": ComplementNB_classifier,\n",
    "    \"SVC\": SVC_classifier,\n",
    "    \"Linear SVC\": LinearSVC_classifier,\n",
    "    \"NuSVC\": NuSVC_classifier\n",
    "}\n",
    "\n",
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'binario_experimento6'\n",
    "pickle.dump(clasificadores, open(filename+'.sav', 'wb'))\n",
    "\n",
    "pickle.dump(testing_set, open('testing_set_'+filename+'.txt', 'wb'))\n",
    "\n",
    "# with open('testing_set_' + filename +'.txt', 'w') as filehandle:\n",
    "#     json.dump(testing_set, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
